{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETR : Finetuning tutorial\n",
    "\n",
    "In this tutorial we're gonna explore how to finetune DETR on the Hard hat Workers dataset: https://public.roboflow.com/object-detection/hard-hat-workers.  \n",
    "\n",
    "<img src=\"../images/hardhatdataset.jpg\"></img>\n",
    "\n",
    "To follow along and  run this notebook, the first things to do is to get the link to download the dataset on this page: https://public.roboflow.com/object-detection/hard-hat-workers\n",
    "\n",
    "- Click on \"raw\"\n",
    "- Then retrieve the download link from \"Tensorflow Object Detection CSV\"\n",
    "- Click on \"show download code\"\n",
    "\n",
    "\n",
    "<img src=\"../images/tutorials/download_hardhat_dataset.png\"></img>\n",
    "\n",
    "\n",
    "Set the download link in the cell bellow\n",
    "\n",
    "<a id=\"cell1\"></a>\n",
    "## 1. Download the Hard Hat Workers Dataset\n",
    "\n",
    "### Download and unzip files\n",
    "\n",
    "Copy paste your download link bellow to download the dataset into your home/data folder (feel free to set the path you want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/thibault/data/hardhat/’: File exists\n",
      "--2021-01-07 12:18:00--  https://public.roboflow.com/ds/t6dXY6HCPO?key=YPgumILnUk\n",
      "Resolving public.roboflow.com (public.roboflow.com)... 151.101.65.195, 151.101.1.195\n",
      "Connecting to public.roboflow.com (public.roboflow.com)|151.101.65.195|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://storage.googleapis.com/roboflow-platform-exports/Ly2DeBzbwsemGd2ReHk4BFxy8683/TlE7G4GXJk3kU7ivmTPR/2/tensorflow.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20210107%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210107T111800Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=0cc6ed4745efc9e726de47280f10a484d5b146a93f046cbe2942891cf18a37def3c80365b89264065013b96e53d81d6f22af41168d7b289d2d9dd8ec7ab146810e55d6f2cb25014be5cbb233ec340341676e128d10312886d7f739e278a4ed9e3780dea1672844f1432a1083faab32640b0a2a7aaf5d67b36a6201fe6cd69826156bfc28f89713129b29ed6b398a32ad34776b30dce075d7ab4374b2415acd1a500a0c057778888df798044009693f90360250056bd29e2fa68e0022d770cb581c79232b8fe4e401aa61cf682b749d7605431950f975a72ac4fc4b1043bd8d9fe144bf88b659d47edb2e834d390d5e004f130892cee93859a2757e5ae5e53985 [following]\n",
      "--2021-01-07 12:18:01--  https://storage.googleapis.com/roboflow-platform-exports/Ly2DeBzbwsemGd2ReHk4BFxy8683/TlE7G4GXJk3kU7ivmTPR/2/tensorflow.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=roboflow-platform%40appspot.gserviceaccount.com%2F20210107%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20210107T111800Z&X-Goog-Expires=901&X-Goog-SignedHeaders=host&X-Goog-Signature=0cc6ed4745efc9e726de47280f10a484d5b146a93f046cbe2942891cf18a37def3c80365b89264065013b96e53d81d6f22af41168d7b289d2d9dd8ec7ab146810e55d6f2cb25014be5cbb233ec340341676e128d10312886d7f739e278a4ed9e3780dea1672844f1432a1083faab32640b0a2a7aaf5d67b36a6201fe6cd69826156bfc28f89713129b29ed6b398a32ad34776b30dce075d7ab4374b2415acd1a500a0c057778888df798044009693f90360250056bd29e2fa68e0022d770cb581c79232b8fe4e401aa61cf682b749d7605431950f975a72ac4fc4b1043bd8d9fe144bf88b659d47edb2e834d390d5e004f130892cee93859a2757e5ae5e53985\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 216.58.198.208, 216.58.215.48, 172.217.19.240, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|216.58.198.208|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 244369097 (233M) [application/zip]\n",
      "Saving to: ‘/home/thibault/data/hardhat/hard-hat-workers-dataset.zip’\n",
      "\n",
      "/home/thibault/data 100%[===================>] 233.05M  7.17MB/s    in 39s     \n",
      "\n",
      "2021-01-07 12:18:40 (6.01 MB/s) - ‘/home/thibault/data/hardhat/hard-hat-workers-dataset.zip’ saved [244369097/244369097]\n",
      "\n",
      "Archive:  /home/thibault/data/hardhat/hard-hat-workers-dataset.zip\n",
      "replace /home/thibault/data/hardhat/test/006637_jpg.rf.012e99d80844459254e586c7aa45adac.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
      "hard-hat-workers-dataset.zip  README.roboflow.txt  train\n",
      "README.dataset.txt\t      test\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/data/hardhat/\n",
    "!wget -O ~/data/hardhat/hard-hat-workers-dataset.zip https://public.roboflow.com/ds/t6dXY6HCPO?key=YPgumILnUk\n",
    "!unzip ~/data/hardhat/hard-hat-workers-dataset.zip -d ~/data/hardhat/\n",
    "!ls ~/data/hardhat/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add detr_tf to your PYTHONPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Set the path to the repository here\n",
    "sys.path.append(\"../\")\n",
    "import detr_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If you're GPU is use for graphical display, you might need the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) == 1:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create your training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf.training_config import TrainingConfig\n",
    "from os.path import expanduser\n",
    "import os\n",
    "\n",
    "class CustomConfig(TrainingConfig):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()        \n",
    "        # Dataset info\n",
    "        self.datadir = os.path.join(expanduser(\"~\"), \"data/hardhat/\")\n",
    "        # The model is trained using fixed size images.\n",
    "        # The following is the desired target image size, but it can be change based on your\n",
    "        # dataset\n",
    "        self.image_size = (480, 720)\n",
    "        # Batch size\n",
    "        self.batch_size = 1\n",
    "        # Using the target batch siz , the training loop will agregate the gradient on 38 steps\n",
    "        # before to update the weights\n",
    "        self.target_batch_size = 38\n",
    "\n",
    "config = CustomConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Hard Hat Workers Dataset\n",
    "Please, checkout the **How to load a dataset** notebook on the repository for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names ['background', 'head', 'helmet']\n"
     ]
    }
   ],
   "source": [
    "from detr_tf.data import load_tfcsv_dataset\n",
    "\n",
    "# Load the dataset and exclude the person class (for some reason not all person are labeled on the training set)\n",
    "train_iterator, class_names = load_tfcsv_dataset(\"train\", config.batch_size, config, augmentation=True, exclude=[\"person\"])\n",
    "valid_iterator, class_names = load_tfcsv_dataset(\"test\", config.batch_size, config, augmentation=True, exclude=[\"person\"])\n",
    "print(\"class_names\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the DETR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights from weights/detr/detr.ckpt\n",
      "Model: \"detr_finetuning\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, None,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "detr (Functional)               (6, None, 100, 256)  41449152    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pos_layer (Sequential)          (6, None, 100, 4)    132612      detr[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "cls_layer (Dense)               (6, None, 100, 3)    771         detr[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_6 (Te [(None, 100, 4)]     0           pos_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_5 (Te [(None, 100, 3)]     0           cls_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_8 (Te [(None, 100, 4)]     0           pos_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_7 (Te [(None, 100, 3)]     0           cls_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_10 (T [(None, 100, 4)]     0           pos_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_9 (Te [(None, 100, 3)]     0           cls_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_12 (T [(None, 100, 4)]     0           pos_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_11 (T [(None, 100, 3)]     0           cls_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_14 (T [(None, 100, 4)]     0           pos_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_13 (T [(None, 100, 3)]     0           cls_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_4 (Te [(None, 100, 4)]     0           pos_layer[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice_3 (Te [(None, 100, 3)]     0           cls_layer[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 41,582,535\n",
      "Trainable params: 41,476,295\n",
      "Non-trainable params: 106,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from detr_tf.networks.detr import get_detr_model\n",
    "# Load the pretrained DETR model with new heads at the top\n",
    "# include_top: We do not include the last layers that predicts the bbox pos and class (include_top=False)\n",
    "# nb_class: We add new layers on top of the model to predicts the bbox pos and class with three class (nb_class=3), background, helmet, face\n",
    "# weights: Use the \"detr\" weight to init the model\n",
    "detr = get_detr_model(config, include_top=False, nb_class=3, weights=\"detr\")\n",
    "detr.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, change the config to train  only the layers on top of the transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/finetune the transformers only\n",
    "config.train_backbone = tf.Variable(False)\n",
    "config.train_transformers = tf.Variable(False)\n",
    "config.train_nlayers = tf.Variable(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the last layers learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.nlayers_lr = tf.Variable(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf.optimizers import setup_optimizers\n",
    "# Setup the optimziers and the trainable variables\n",
    "optimzers = setup_optimizers(detr, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the last layers on top of the transformer for one epoch\n",
    "\n",
    "- **ce** is the cross entropy loss of the layer that predicts the bbox class\n",
    "- **giou** and **l1** loss are the positional loss  of the layer that predicts the bbox pos (center_x, center_y, width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0], \t Step: [0], \t ce: [0.83] \t giou : [1.07] \t l1 : [0.81] \t time : [0.00]\n",
      "Epoch: [0], \t Step: [100], \t ce: [1.21] \t giou : [1.25] \t l1 : [0.23] \t time : [35.48]\n",
      "Epoch: [0], \t Step: [200], \t ce: [0.83] \t giou : [0.91] \t l1 : [0.16] \t time : [24.27]\n",
      "Epoch: [0], \t Step: [300], \t ce: [0.35] \t giou : [1.08] \t l1 : [0.32] \t time : [23.86]\n",
      "Epoch: [0], \t Step: [400], \t ce: [1.44] \t giou : [0.97] \t l1 : [0.09] \t time : [24.09]\n",
      "Epoch: [0], \t Step: [500], \t ce: [0.51] \t giou : [0.61] \t l1 : [0.14] \t time : [24.00]\n",
      "Epoch: [0], \t Step: [600], \t ce: [0.55] \t giou : [0.51] \t l1 : [0.11] \t time : [24.83]\n",
      "Epoch: [0], \t Step: [700], \t ce: [0.85] \t giou : [0.73] \t l1 : [0.13] \t time : [24.50]\n",
      "Epoch: [0], \t Step: [800], \t ce: [0.42] \t giou : [0.54] \t l1 : [0.17] \t time : [24.94]\n",
      "Epoch: [0], \t Step: [900], \t ce: [1.14] \t giou : [0.92] \t l1 : [0.08] \t time : [24.19]\n",
      "Epoch: [0], \t Step: [1000], \t ce: [0.39] \t giou : [0.74] \t l1 : [0.05] \t time : [24.71]\n",
      "Epoch: [0], \t Step: [1100], \t ce: [0.87] \t giou : [0.65] \t l1 : [0.12] \t time : [24.88]\n",
      "Epoch: [0], \t Step: [1200], \t ce: [0.43] \t giou : [0.78] \t l1 : [0.04] \t time : [24.48]\n",
      "Epoch: [0], \t Step: [1300], \t ce: [0.46] \t giou : [0.78] \t l1 : [0.15] \t time : [24.35]\n",
      "Epoch: [0], \t Step: [1400], \t ce: [0.46] \t giou : [1.58] \t l1 : [0.38] \t time : [25.15]\n",
      "Epoch: [0], \t Step: [1500], \t ce: [0.93] \t giou : [0.81] \t l1 : [0.08] \t time : [25.20]\n",
      "Epoch: [0], \t Step: [1600], \t ce: [0.39] \t giou : [0.43] \t l1 : [0.13] \t time : [24.20]\n",
      "Epoch: [0], \t Step: [1700], \t ce: [0.60] \t giou : [1.02] \t l1 : [0.21] \t time : [24.72]\n",
      "Epoch: [0], \t Step: [1800], \t ce: [0.96] \t giou : [0.66] \t l1 : [0.12] \t time : [24.87]\n"
     ]
    }
   ],
   "source": [
    "from detr_tf import training\n",
    "training.fit(detr, train_iterator, optimzers, config, epoch_nb=0, class_names=class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check the training results after one epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detr_tf import get_model_inference\n",
    "\n",
    "for valid_images, target_bbox, target_class in valid_iterator:\n",
    "    model_outputs = detr(valid_images)\n",
    "    predicted_bbox, predicted_labels, predicted_scores = get_model_inference(elem_m_outputs, config.background_class, bbox_format=\"xyxy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
